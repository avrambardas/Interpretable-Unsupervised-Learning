{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "36TvLMLNKjS3"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import site\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cd, euclidean_distances as ed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, maxabs_scale\n",
    "from tensorflow.keras import layers, losses, callbacks, Sequential\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rhBDi32fKq96"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(int(input_dim/2)+2, activation='tanh'),\n",
    "            tf.keras.layers.Dense(int(input_dim/2)+1, activation='tanh'),\n",
    "            tf.keras.layers.Dense(latent_dim, activation='tanh'),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(int(input_dim/2)+1, activation='tanh'),\n",
    "            tf.keras.layers.Dense(int(input_dim/2)+2, activation='tanh'),\n",
    "            tf.keras.layers.Dense(input_dim, activation='tanh'),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size: 10\n",
      "Feature size: 20\n",
      "Feature size: 30\n",
      "Feature size: 40\n",
      "Feature size: 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# range(150,1050,50): #Edw tha vgei to neural!\n",
    "for features in [10, 20, 30, 40, 50]:\n",
    "    print('Feature size:', features)\n",
    "    feature_names = ['F'+str(i) for i in range(features)]\n",
    "    x, y = make_classification(n_samples=1000, n_features=features, n_informative=int(\n",
    "        features/2), n_redundant=int(features/4), n_classes=2, shuffle=True, random_state=1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = MaxAbsScaler().fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    mean = x_train.mean(axis=0)\n",
    "\n",
    "    pca = PCA(int(features/2), random_state=42)\n",
    "    pca.fit(x_train, y_train)\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "\n",
    "    kpca = KernelPCA(int(features/2), kernel='rbf', random_state=42)\n",
    "    kpca.fit(x_train, y_train)\n",
    "    x_test_kpca = kpca.transform(x_test)\n",
    "\n",
    "    iso = Isomap(n_components=int(features/2))\n",
    "    iso.fit(x_train, y_train)\n",
    "    x_test_iso = iso.transform(x_test)\n",
    "\n",
    "    #callback = callbacks.EarlyStopping(monitor='loss', patience=3, verbose=0, restore_best_weights=True)\n",
    "    #ae = Autoencoder(len(x_train[0]),int(features/2))\n",
    "    #ae.compile(optimizer='adam', loss='mae')\n",
    "    # ae.fit(x_train, x_train,\n",
    "    #                epochs=200,\n",
    "    #                shuffle=True,\n",
    "    #                validation_split=0.1,\n",
    "    #                callbacks=[callback],\n",
    "    #                verbose=0)\n",
    "    #x_test_ae = ae.predict(x_test)\n",
    "\n",
    "    for ltype in ['locallocal']:\n",
    "        for ng_technique in ['KNN', 'LatentKNN', 'Clustering']:  # 'KNN', 'LatentKNN',\n",
    "            lxdr_pca = LXDR(pca, feature_names, x_train, mean=mean)\n",
    "            lxdr_kpca = LXDR(kpca, feature_names, x_train)\n",
    "            lxdr_iso = LXDR(iso, feature_names, x_train)\n",
    "            #lxdr_ae =  LXDR(ae, feature_names, x_train)\n",
    "\n",
    "            lxdr_pca.type = ltype\n",
    "            lxdr_kpca.type = ltype\n",
    "            lxdr_iso.type = ltype\n",
    "            #lxdr_ae.type = ltype\n",
    "\n",
    "            if ng_technique == 'KNN':\n",
    "                lxdr_pca._set_knn_local()\n",
    "                lxdr_kpca._set_knn_local()\n",
    "                lxdr_iso._set_knn_local()\n",
    "                # lxdr_ae._set_knn_local()\n",
    "            elif ng_technique == 'LatentKNN':\n",
    "                lxdr_pca._set_knn_latent_local()\n",
    "                lxdr_kpca._set_knn_latent_local()\n",
    "                lxdr_iso._set_knn_latent_local()\n",
    "                # lxdr_ae._set_knn_latent_local()\n",
    "            # 10, 50, int(1000/10), int(1000/5), int(2*1000/4),\n",
    "            for n in [10, 50, int(1000/10), int(1000/5), int(2*1000/4), int(3*1000/4)]:\n",
    "                if ng_technique == 'Clustering':\n",
    "                    lxdr_pca.birch = {}\n",
    "                    lxdr_kpca.birch = {}\n",
    "                    lxdr_iso.birch = {}\n",
    "                    #lxdr_ae.birch = {}\n",
    "                pca_weights = [[], [], [], []]\n",
    "                pca_instance = [[], [], [], []]\n",
    "                kpca_instance = [[], [], [], []]\n",
    "                iso_instance = [[], [], [], []]\n",
    "                #ae_instance = [[],[],[],[]]\n",
    "                instance = 0\n",
    "                for x in x_test:\n",
    "                    ts = time.time()\n",
    "                    weights_pca = lxdr_pca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    a = pca.components_.reshape((1, -1))[0]\n",
    "                    b = np.array(weights_pca).reshape((1, -1))[0]\n",
    "                    pca_weights[0].append(ed([a], [b])[0][0])\n",
    "                    pca_weights[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_weights[2].append(mae([a], [b]))\n",
    "                    pca_weights[3].append(te)\n",
    "                    ldrx_instance = np.dot(x-mean, weights_pca.T)\n",
    "                    a = x_test_pca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    pca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    pca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_instance[2].append(mae([a], [b]))\n",
    "                    pca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_kpca = lxdr_kpca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_kpca.T)\n",
    "                    a = x_test_kpca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    kpca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    kpca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    kpca_instance[2].append(mae([a], [b]))\n",
    "                    kpca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_iso = lxdr_iso.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_iso.T)\n",
    "                    a = x_test_iso[instance]\n",
    "                    b = ldrx_instance\n",
    "                    iso_instance[0].append(ed([a], [b])[0][0])\n",
    "                    iso_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    iso_instance[2].append(mae([a], [b]))\n",
    "                    iso_instance[3].append(te)\n",
    "\n",
    "                    #ts = time.time()\n",
    "                    #weights_ae = lxdr_ae.explain_instance(x, n, auto_alpha=True, ng_technique = ng_technique)\n",
    "                    #te = time.time()-ts\n",
    "                    #ldrx_instance = np.dot(x, weights_ae.T)\n",
    "                    #a = x_test_ae[instance]\n",
    "                    #b = ldrx_instance\n",
    "                    # ae_instance[0].append(ed([a],[b])[0][0])\n",
    "                    # ae_instance[1].append(1-cd([a],[b])[0][0])\n",
    "                    # ae_instance[2].append(mae([a],[b]))\n",
    "                    # ae_instance[3].append(te)\n",
    "\n",
    "                    instance = instance + 1\n",
    "                with open('scalability_15-01-2023.csv', 'a', encoding='UTF8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    siz = len(x_test)\n",
    "                    writer.writerow([features, 'pca_w', ltype, ng_technique, n, np.mean(pca_weights[0]), np.mean(\n",
    "                        pca_weights[1]), np.mean(pca_weights[2]), np.mean(pca_weights[3])])\n",
    "                    writer.writerow([features, 'pca_i', ltype, ng_technique, n, np.mean(pca_instance[0]), np.mean(\n",
    "                        pca_instance[1]), np.mean(pca_instance[2]), np.mean(pca_instance[3])])\n",
    "                    writer.writerow([features, 'kpca', ltype, ng_technique, n, np.mean(kpca_instance[0]), np.mean(\n",
    "                        kpca_instance[1]), np.mean(kpca_instance[2]), np.mean(kpca_instance[3])])\n",
    "                    writer.writerow([features, 'iso', ltype, ng_technique, n, np.mean(iso_instance[0]), np.mean(\n",
    "                        iso_instance[1]), np.mean(iso_instance[2]), np.mean(iso_instance[3])])\n",
    "                    #writer.writerow([features,'ae', ltype, ng_technique, n, np.mean(ae_instance[0]), np.mean(ae_instance[1]), np.mean(ae_instance[2]), np.mean(ae_instance[3])])\n",
    "\n",
    "    for ltype in ['classic', 'neural']:\n",
    "        lxdr_pca.type = ltype\n",
    "        lxdr_kpca.type = ltype\n",
    "        lxdr_iso.type = ltype\n",
    "        #lxdr_ae.type = ltype\n",
    "        # 'Global', 'KNN', 'LatentKNN',\n",
    "        for ng_technique in ['Global', 'KNN', 'LatentKNN', 'Clustering']:\n",
    "            number_of_neigbours = [10, 50, int(\n",
    "                1000/10), int(1000/5), int(2*1000/4), int(3*1000/4)]\n",
    "            lxdr_pca = LXDR(pca, feature_names, x_train, mean=mean)\n",
    "            lxdr_kpca = LXDR(kpca, feature_names, x_train)\n",
    "            lxdr_iso = LXDR(iso, feature_names, x_train)\n",
    "            #lxdr_ae =  LXDR(ae, feature_names, x_train)\n",
    "\n",
    "            lxdr_pca.type = ltype\n",
    "            lxdr_kpca.type = ltype\n",
    "            lxdr_iso.type = ltype\n",
    "            #lxdr_ae.type = ltype\n",
    "\n",
    "            if ng_technique == 'KNN':\n",
    "                lxdr_pca._set_knn()\n",
    "                lxdr_kpca._set_knn()\n",
    "                lxdr_iso._set_knn()\n",
    "                # lxdr_ae._set_knn()\n",
    "            elif ng_technique == 'LatentKNN':\n",
    "                lxdr_pca._set_knn_latent()\n",
    "                lxdr_kpca._set_knn_latent()\n",
    "                lxdr_iso._set_knn_latent()\n",
    "                # lxdr_ae._set_knn_latent()\n",
    "            if ng_technique == 'Global':\n",
    "                number_of_neigbours = [len(x_train)]\n",
    "                lxdr_pca.global_ = {}\n",
    "                lxdr_kpca.global_ = {}\n",
    "                lxdr_iso.global_ = {}\n",
    "                #lxdr_ae.global_ = {}\n",
    "            for n in number_of_neigbours:\n",
    "                if ng_technique == 'Clustering':\n",
    "                    lxdr_pca.birch = {}\n",
    "                    lxdr_kpca.birch = {}\n",
    "                    lxdr_iso.birch = {}\n",
    "                    #lxdr_ae.birch = {}\n",
    "                pca_weights = [[], [], [], []]\n",
    "                pca_instance = [[], [], [], []]\n",
    "                kpca_instance = [[], [], [], []]\n",
    "                iso_instance = [[], [], [], []]\n",
    "                #ae_instance = [[],[],[],[]]\n",
    "                instance = 0\n",
    "                for x in x_test:\n",
    "                    ts = time.time()\n",
    "                    weights_pca = lxdr_pca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    a = pca.components_.reshape((1, -1))[0]\n",
    "                    b = np.array(weights_pca).reshape((1, -1))[0]\n",
    "                    pca_weights[0].append(ed([a], [b])[0][0])\n",
    "                    pca_weights[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_weights[2].append(mae([a], [b]))\n",
    "                    pca_weights[3].append(te)\n",
    "                    ldrx_instance = np.dot(x-mean, weights_pca.T)\n",
    "                    a = x_test_pca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    pca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    pca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_instance[2].append(mae([a], [b]))\n",
    "                    pca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_kpca = lxdr_kpca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_kpca.T)\n",
    "                    a = x_test_kpca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    kpca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    kpca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    kpca_instance[2].append(mae([a], [b]))\n",
    "                    kpca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_iso = lxdr_iso.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_iso.T)\n",
    "                    a = x_test_iso[instance]\n",
    "                    b = ldrx_instance\n",
    "                    iso_instance[0].append(ed([a], [b])[0][0])\n",
    "                    iso_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    iso_instance[2].append(mae([a], [b]))\n",
    "                    iso_instance[3].append(te)\n",
    "\n",
    "                    #ts = time.time()\n",
    "                    #weights_ae = lxdr_ae.explain_instance(x, n, auto_alpha=True, ng_technique = ng_technique)\n",
    "                    #te = time.time()-ts\n",
    "                    #ldrx_instance = np.dot(x, weights_ae.T)\n",
    "                    #a = x_test_ae[instance]\n",
    "                    #b = ldrx_instance\n",
    "                    # ae_instance[0].append(ed([a],[b])[0][0])\n",
    "                    # ae_instance[1].append(1-cd([a],[b])[0][0])\n",
    "                    # ae_instance[2].append(mae([a],[b]))\n",
    "                    # ae_instance[3].append(te)\n",
    "\n",
    "                    instance = instance + 1\n",
    "                with open('scalability_15-01-2023.csv', 'a', encoding='UTF8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    siz = len(x_test)\n",
    "                    writer.writerow([features, 'pca_w', ltype, ng_technique, n, np.mean(pca_weights[0]), np.mean(\n",
    "                        pca_weights[1]), np.mean(pca_weights[2]), np.mean(pca_weights[3])])\n",
    "                    writer.writerow([features, 'pca_i', ltype, ng_technique, n, np.mean(pca_instance[0]), np.mean(\n",
    "                        pca_instance[1]), np.mean(pca_instance[2]), np.mean(pca_instance[3])])\n",
    "                    writer.writerow([features, 'kpca', ltype, ng_technique, n, np.mean(kpca_instance[0]), np.mean(\n",
    "                        kpca_instance[1]), np.mean(kpca_instance[2]), np.mean(kpca_instance[3])])\n",
    "                    writer.writerow([features, 'iso', ltype, ng_technique, n, np.mean(iso_instance[0]), np.mean(\n",
    "                        iso_instance[1]), np.mean(iso_instance[2]), np.mean(iso_instance[3])])\n",
    "                    #writer.writerow([features,'ae', ltype, ng_technique, n, np.mean(ae_instance[0]), np.mean(ae_instance[1]), np.mean(ae_instance[2]), np.mean(ae_instance[3])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8],\n",
       "       [8, 2, 3],\n",
       "       [0, 8, 2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1, 2, 3], [0, 1, 2]]\n",
    "b = [[3, 4, 5], [6, 7, 8]]\n",
    "c = [[8, 2, 3], [0, 8, 2]]\n",
    "np.concatenate([a, b, c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size: 100\n",
      "Feature size: 150\n",
      "Feature size: 200\n",
      "Feature size: 250\n",
      "Feature size: 300\n",
      "Feature size: 350\n",
      "Feature size: 400\n",
      "Feature size: 450\n",
      "Feature size: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# range(150,1050,50): #Edw tha vgei to neural!\n",
    "for features in [100, 150, 200, 250, 300, 350, 400, 450, 500]:\n",
    "    print('Feature size:', features)\n",
    "    feature_names = ['F'+str(i) for i in range(features)]\n",
    "    x, y = make_classification(n_samples=1000, n_features=features, n_informative=int(\n",
    "        features/2), n_redundant=int(features/4), n_classes=2, shuffle=True, random_state=1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = MaxAbsScaler().fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    mean = x_train.mean(axis=0)\n",
    "\n",
    "    pca = PCA(int(features/2), random_state=42)\n",
    "    pca.fit(x_train, y_train)\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "\n",
    "    kpca = KernelPCA(int(features/2), kernel='rbf', random_state=42)\n",
    "    kpca.fit(x_train, y_train)\n",
    "    x_test_kpca = kpca.transform(x_test)\n",
    "\n",
    "    iso = Isomap(n_components=int(features/2))\n",
    "    iso.fit(x_train, y_train)\n",
    "    x_test_iso = iso.transform(x_test)\n",
    "\n",
    "    #callback = callbacks.EarlyStopping(monitor='loss', patience=3, verbose=0, restore_best_weights=True)\n",
    "    #ae = Autoencoder(len(x_train[0]),int(features/2))\n",
    "    #ae.compile(optimizer='adam', loss='mae')\n",
    "    # ae.fit(x_train, x_train,\n",
    "    #                epochs=200,\n",
    "    #                shuffle=True,\n",
    "    #                validation_split=0.1,\n",
    "    #                callbacks=[callback],\n",
    "    #                verbose=0)\n",
    "    #x_test_ae = ae.predict(x_test)\n",
    "\n",
    "    for ltype in ['locallocal']:\n",
    "        for ng_technique in ['KNN', 'LatentKNN', 'Clustering']:  # 'KNN', 'LatentKNN',\n",
    "            lxdr_pca = LXDR(pca, feature_names, x_train, mean=mean)\n",
    "            lxdr_kpca = LXDR(kpca, feature_names, x_train)\n",
    "            lxdr_iso = LXDR(iso, feature_names, x_train)\n",
    "            #lxdr_ae =  LXDR(ae, feature_names, x_train)\n",
    "\n",
    "            lxdr_pca.type = ltype\n",
    "            lxdr_kpca.type = ltype\n",
    "            lxdr_iso.type = ltype\n",
    "            #lxdr_ae.type = ltype\n",
    "\n",
    "            if ng_technique == 'KNN':\n",
    "                lxdr_pca._set_knn_local()\n",
    "                lxdr_kpca._set_knn_local()\n",
    "                lxdr_iso._set_knn_local()\n",
    "                # lxdr_ae._set_knn_local()\n",
    "            elif ng_technique == 'LatentKNN':\n",
    "                lxdr_pca._set_knn_latent_local()\n",
    "                lxdr_kpca._set_knn_latent_local()\n",
    "                lxdr_iso._set_knn_latent_local()\n",
    "                # lxdr_ae._set_knn_latent_local()\n",
    "            # 10, 50, int(1000/10), int(1000/5), int(2*1000/4),\n",
    "            for n in [10, 50, int(1000/10), int(1000/5), int(2*1000/4), int(3*1000/4)]:\n",
    "                if ng_technique == 'Clustering':\n",
    "                    lxdr_pca.birch = {}\n",
    "                    lxdr_kpca.birch = {}\n",
    "                    lxdr_iso.birch = {}\n",
    "                    #lxdr_ae.birch = {}\n",
    "                pca_weights = [[], [], [], []]\n",
    "                pca_instance = [[], [], [], []]\n",
    "                kpca_instance = [[], [], [], []]\n",
    "                iso_instance = [[], [], [], []]\n",
    "                #ae_instance = [[],[],[],[]]\n",
    "                instance = 0\n",
    "                for x in x_test:\n",
    "                    ts = time.time()\n",
    "                    weights_pca = lxdr_pca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    a = pca.components_.reshape((1, -1))[0]\n",
    "                    b = np.array(weights_pca).reshape((1, -1))[0]\n",
    "                    pca_weights[0].append(ed([a], [b])[0][0])\n",
    "                    pca_weights[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_weights[2].append(mae([a], [b]))\n",
    "                    pca_weights[3].append(te)\n",
    "                    ldrx_instance = np.dot(x-mean, weights_pca.T)\n",
    "                    a = x_test_pca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    pca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    pca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_instance[2].append(mae([a], [b]))\n",
    "                    pca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_kpca = lxdr_kpca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_kpca.T)\n",
    "                    a = x_test_kpca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    kpca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    kpca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    kpca_instance[2].append(mae([a], [b]))\n",
    "                    kpca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_iso = lxdr_iso.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_iso.T)\n",
    "                    a = x_test_iso[instance]\n",
    "                    b = ldrx_instance\n",
    "                    iso_instance[0].append(ed([a], [b])[0][0])\n",
    "                    iso_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    iso_instance[2].append(mae([a], [b]))\n",
    "                    iso_instance[3].append(te)\n",
    "\n",
    "                    #ts = time.time()\n",
    "                    #weights_ae = lxdr_ae.explain_instance(x, n, auto_alpha=True, ng_technique = ng_technique)\n",
    "                    #te = time.time()-ts\n",
    "                    #ldrx_instance = np.dot(x, weights_ae.T)\n",
    "                    #a = x_test_ae[instance]\n",
    "                    #b = ldrx_instance\n",
    "                    # ae_instance[0].append(ed([a],[b])[0][0])\n",
    "                    # ae_instance[1].append(1-cd([a],[b])[0][0])\n",
    "                    # ae_instance[2].append(mae([a],[b]))\n",
    "                    # ae_instance[3].append(te)\n",
    "\n",
    "                    instance = instance + 1\n",
    "                with open('scalability_15-01-2023.csv', 'a', encoding='UTF8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    siz = len(x_test)\n",
    "                    writer.writerow([features, 'pca_w', ltype, ng_technique, n, np.mean(pca_weights[0]), np.mean(\n",
    "                        pca_weights[1]), np.mean(pca_weights[2]), np.mean(pca_weights[3])])\n",
    "                    writer.writerow([features, 'pca_i', ltype, ng_technique, n, np.mean(pca_instance[0]), np.mean(\n",
    "                        pca_instance[1]), np.mean(pca_instance[2]), np.mean(pca_instance[3])])\n",
    "                    writer.writerow([features, 'kpca', ltype, ng_technique, n, np.mean(kpca_instance[0]), np.mean(\n",
    "                        kpca_instance[1]), np.mean(kpca_instance[2]), np.mean(kpca_instance[3])])\n",
    "                    writer.writerow([features, 'iso', ltype, ng_technique, n, np.mean(iso_instance[0]), np.mean(\n",
    "                        iso_instance[1]), np.mean(iso_instance[2]), np.mean(iso_instance[3])])\n",
    "                    #writer.writerow([features,'ae', ltype, ng_technique, n, np.mean(ae_instance[0]), np.mean(ae_instance[1]), np.mean(ae_instance[2]), np.mean(ae_instance[3])])\n",
    "\n",
    "    for ltype in ['classic']:\n",
    "        lxdr_pca.type = ltype\n",
    "        lxdr_kpca.type = ltype\n",
    "        lxdr_iso.type = ltype\n",
    "        #lxdr_ae.type = ltype\n",
    "        # 'Global', 'KNN', 'LatentKNN',\n",
    "        for ng_technique in ['Global', 'KNN', 'LatentKNN', 'Clustering']:\n",
    "            number_of_neigbours = [10, 50, int(\n",
    "                1000/10), int(1000/5), int(2*1000/4), int(3*1000/4)]\n",
    "            lxdr_pca = LXDR(pca, feature_names, x_train, mean=mean)\n",
    "            lxdr_kpca = LXDR(kpca, feature_names, x_train)\n",
    "            lxdr_iso = LXDR(iso, feature_names, x_train)\n",
    "            #lxdr_ae =  LXDR(ae, feature_names, x_train)\n",
    "\n",
    "            lxdr_pca.type = ltype\n",
    "            lxdr_kpca.type = ltype\n",
    "            lxdr_iso.type = ltype\n",
    "            #lxdr_ae.type = ltype\n",
    "\n",
    "            if ng_technique == 'KNN':\n",
    "                lxdr_pca._set_knn()\n",
    "                lxdr_kpca._set_knn()\n",
    "                lxdr_iso._set_knn()\n",
    "                # lxdr_ae._set_knn()\n",
    "            elif ng_technique == 'LatentKNN':\n",
    "                lxdr_pca._set_knn_latent()\n",
    "                lxdr_kpca._set_knn_latent()\n",
    "                lxdr_iso._set_knn_latent()\n",
    "                # lxdr_ae._set_knn_latent()\n",
    "            if ng_technique == 'Global':\n",
    "                number_of_neigbours = [len(x_train)]\n",
    "                lxdr_pca.global_ = {}\n",
    "                lxdr_kpca.global_ = {}\n",
    "                lxdr_iso.global_ = {}\n",
    "                #lxdr_ae.global_ = {}\n",
    "            for n in number_of_neigbours:\n",
    "                if ng_technique == 'Clustering':\n",
    "                    lxdr_pca.birch = {}\n",
    "                    lxdr_kpca.birch = {}\n",
    "                    lxdr_iso.birch = {}\n",
    "                    #lxdr_ae.birch = {}\n",
    "                pca_weights = [[], [], [], []]\n",
    "                pca_instance = [[], [], [], []]\n",
    "                kpca_instance = [[], [], [], []]\n",
    "                iso_instance = [[], [], [], []]\n",
    "                #ae_instance = [[],[],[],[]]\n",
    "                instance = 0\n",
    "                for x in x_test:\n",
    "                    ts = time.time()\n",
    "                    weights_pca = lxdr_pca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    a = pca.components_.reshape((1, -1))[0]\n",
    "                    b = np.array(weights_pca).reshape((1, -1))[0]\n",
    "                    pca_weights[0].append(ed([a], [b])[0][0])\n",
    "                    pca_weights[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_weights[2].append(mae([a], [b]))\n",
    "                    pca_weights[3].append(te)\n",
    "                    ldrx_instance = np.dot(x-mean, weights_pca.T)\n",
    "                    a = x_test_pca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    pca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    pca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_instance[2].append(mae([a], [b]))\n",
    "                    pca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_kpca = lxdr_kpca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_kpca.T)\n",
    "                    a = x_test_kpca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    kpca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    kpca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    kpca_instance[2].append(mae([a], [b]))\n",
    "                    kpca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_iso = lxdr_iso.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_iso.T)\n",
    "                    a = x_test_iso[instance]\n",
    "                    b = ldrx_instance\n",
    "                    iso_instance[0].append(ed([a], [b])[0][0])\n",
    "                    iso_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    iso_instance[2].append(mae([a], [b]))\n",
    "                    iso_instance[3].append(te)\n",
    "\n",
    "                    #ts = time.time()\n",
    "                    #weights_ae = lxdr_ae.explain_instance(x, n, auto_alpha=True, ng_technique = ng_technique)\n",
    "                    #te = time.time()-ts\n",
    "                    #ldrx_instance = np.dot(x, weights_ae.T)\n",
    "                    #a = x_test_ae[instance]\n",
    "                    #b = ldrx_instance\n",
    "                    # ae_instance[0].append(ed([a],[b])[0][0])\n",
    "                    # ae_instance[1].append(1-cd([a],[b])[0][0])\n",
    "                    # ae_instance[2].append(mae([a],[b]))\n",
    "                    # ae_instance[3].append(te)\n",
    "\n",
    "                    instance = instance + 1\n",
    "                with open('scalability_15-01-2023.csv', 'a', encoding='UTF8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    siz = len(x_test)\n",
    "                    writer.writerow([features, 'pca_w', ltype, ng_technique, n, np.mean(pca_weights[0]), np.mean(\n",
    "                        pca_weights[1]), np.mean(pca_weights[2]), np.mean(pca_weights[3])])\n",
    "                    writer.writerow([features, 'pca_i', ltype, ng_technique, n, np.mean(pca_instance[0]), np.mean(\n",
    "                        pca_instance[1]), np.mean(pca_instance[2]), np.mean(pca_instance[3])])\n",
    "                    writer.writerow([features, 'kpca', ltype, ng_technique, n, np.mean(kpca_instance[0]), np.mean(\n",
    "                        kpca_instance[1]), np.mean(kpca_instance[2]), np.mean(kpca_instance[3])])\n",
    "                    writer.writerow([features, 'iso', ltype, ng_technique, n, np.mean(iso_instance[0]), np.mean(\n",
    "                        iso_instance[1]), np.mean(iso_instance[2]), np.mean(iso_instance[3])])\n",
    "                    #writer.writerow([features,'ae', ltype, ng_technique, n, np.mean(ae_instance[0]), np.mean(ae_instance[1]), np.mean(ae_instance[2]), np.mean(ae_instance[3])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3bB4Lb3OzVM",
    "outputId": "87b8e612-0dc3-4aa6-b35e-875f03734ebe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# 10, 20, 30, 40 DONE\n",
    "# range(150,1050,50): #Edw tha vgei to neural!\n",
    "for features in [30, 40, 50, 100]:\n",
    "    print('Feature size:', features)\n",
    "    feature_names = ['F'+str(i) for i in range(features)]\n",
    "    x, y = make_classification(n_samples=1000, n_features=features, n_informative=int(\n",
    "        features/2), n_redundant=int(features/4), n_classes=2, shuffle=True, random_state=1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = MaxAbsScaler().fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    mean = x_train.mean(axis=0)\n",
    "\n",
    "    pca = PCA(int(features/2), random_state=42)\n",
    "    pca.fit(x_train, y_train)\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "\n",
    "    kpca = KernelPCA(int(features/2), random_state=42)\n",
    "    kpca.fit(x_train, y_train)\n",
    "    x_test_kpca = kpca.transform(x_test)\n",
    "\n",
    "    iso = Isomap(n_components=int(features/2))\n",
    "    iso.fit(x_train, y_train)\n",
    "    x_test_iso = iso.transform(x_test)\n",
    "\n",
    "    callback = callbacks.EarlyStopping(\n",
    "        monitor='loss', patience=3, verbose=0, restore_best_weights=True)\n",
    "    ae = Autoencoder(len(x_train[0]), int(features/2))\n",
    "    ae.compile(optimizer='adam', loss='mae')\n",
    "    ae.fit(x_train, x_train,\n",
    "           epochs=200,\n",
    "           shuffle=True,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[callback],\n",
    "           verbose=0)\n",
    "    x_test_ae = ae.predict(x_test)\n",
    "\n",
    "    lxdr_pca = LXDR(pca, feature_names, x_train, mean=mean)\n",
    "    lxdr_kpca = LXDR(kpca, feature_names, x_train)\n",
    "    lxdr_iso = LXDR(iso, feature_names, x_train)\n",
    "    lxdr_ae = LXDR(ae, feature_names, x_train)\n",
    "\n",
    "    for ltype in ['locallocal']:\n",
    "        lxdr_pca.type = ltype\n",
    "        lxdr_kpca.type = ltype\n",
    "        lxdr_iso.type = ltype\n",
    "        lxdr_ae.type = ltype\n",
    "        for ng_technique in ['KNN', 'LatentKNN', 'Clustering']:\n",
    "            for n in [10, 50, int(1000/10), int(1000/5), int(2*1000/4), int(3*1000/4)]:\n",
    "                pca_weights = [[], [], [], []]\n",
    "                pca_instance = [[], [], [], []]\n",
    "                kpca_instance = [[], [], [], []]\n",
    "                iso_instance = [[], [], [], []]\n",
    "                ae_instance = [[], [], [], []]\n",
    "                instance = 0\n",
    "                for x in x_test:\n",
    "                    ts = time.time()\n",
    "                    weights_pca = lxdr_pca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    a = pca.components_.reshape((1, -1))[0]\n",
    "                    b = np.array(weights_pca).reshape((1, -1))[0]\n",
    "                    pca_weights[0].append(ed([a], [b])[0][0])\n",
    "                    pca_weights[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_weights[2].append(mae([a], [b]))\n",
    "                    pca_weights[3].append(te)\n",
    "                    ldrx_instance = np.dot(x-mean, weights_pca.T)\n",
    "                    a = x_test_pca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    pca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    pca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_instance[2].append(mae([a], [b]))\n",
    "                    pca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_kpca = lxdr_kpca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_kpca.T)\n",
    "                    a = x_test_kpca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    kpca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    kpca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    kpca_instance[2].append(mae([a], [b]))\n",
    "                    kpca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_iso = lxdr_iso.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_iso.T)\n",
    "                    a = x_test_iso[instance]\n",
    "                    b = ldrx_instance\n",
    "                    iso_instance[0].append(ed([a], [b])[0][0])\n",
    "                    iso_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    iso_instance[2].append(mae([a], [b]))\n",
    "                    iso_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_ae = lxdr_ae.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_ae.T)\n",
    "                    a = x_test_ae[instance]\n",
    "                    b = ldrx_instance\n",
    "                    ae_instance[0].append(ed([a], [b])[0][0])\n",
    "                    ae_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    ae_instance[2].append(mae([a], [b]))\n",
    "                    ae_instance[3].append(te)\n",
    "\n",
    "                    instance = instance + 1\n",
    "                with open('scalability_final.csv', 'a', encoding='UTF8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    siz = len(x_test)\n",
    "                    writer.writerow([features, 'pca_w', ltype, ng_technique, n, np.mean(pca_weights[0]), np.mean(\n",
    "                        pca_weights[1]), np.mean(pca_weights[2]), np.mean(pca_weights[3])])\n",
    "                    writer.writerow([features, 'pca_i', ltype, ng_technique, n, np.mean(pca_instance[0]), np.mean(\n",
    "                        pca_instance[1]), np.mean(pca_instance[2]), np.mean(pca_instance[3])])\n",
    "                    writer.writerow([features, 'kpca', ltype, ng_technique, n, np.mean(kpca_instance[0]), np.mean(\n",
    "                        kpca_instance[1]), np.mean(kpca_instance[2]), np.mean(kpca_instance[3])])\n",
    "                    writer.writerow([features, 'iso', ltype, ng_technique, n, np.mean(iso_instance[0]), np.mean(\n",
    "                        iso_instance[1]), np.mean(iso_instance[2]), np.mean(iso_instance[3])])\n",
    "                    writer.writerow([features, 'ae', ltype, ng_technique, n, np.mean(ae_instance[0]), np.mean(\n",
    "                        ae_instance[1]), np.mean(ae_instance[2]), np.mean(ae_instance[3])])\n",
    "\n",
    "    for ltype in ['classic', 'neural']:\n",
    "        lxdr_pca.type = ltype\n",
    "        lxdr_kpca.type = ltype\n",
    "        lxdr_iso.type = ltype\n",
    "        lxdr_ae.type = ltype\n",
    "        for ng_technique in ['Global', 'KNN', 'LatentKNN', 'Clustering']:\n",
    "            number_of_neigbours = [10, 50, int(\n",
    "                1000/10), int(1000/5), int(2*1000/4), int(3*1000/4)]\n",
    "            if ng_technique == 'Global':\n",
    "                number_of_neigbours = [len(x_train)]\n",
    "                lxdr_pca.global_ = {}\n",
    "                lxdr_kpca.global_ = {}\n",
    "                lxdr_iso.global_ = {}\n",
    "                lxdr_ae.global_ = {}\n",
    "            for n in number_of_neigbours:\n",
    "                pca_weights = [[], [], [], []]\n",
    "                pca_instance = [[], [], [], []]\n",
    "                kpca_instance = [[], [], [], []]\n",
    "                iso_instance = [[], [], [], []]\n",
    "                ae_instance = [[], [], [], []]\n",
    "                instance = 0\n",
    "                for x in x_test:\n",
    "                    ts = time.time()\n",
    "                    weights_pca = lxdr_pca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    a = pca.components_.reshape((1, -1))[0]\n",
    "                    b = np.array(weights_pca).reshape((1, -1))[0]\n",
    "                    pca_weights[0].append(ed([a], [b])[0][0])\n",
    "                    pca_weights[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_weights[2].append(mae([a], [b]))\n",
    "                    pca_weights[3].append(te)\n",
    "                    ldrx_instance = np.dot(x-mean, weights_pca.T)\n",
    "                    a = x_test_pca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    pca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    pca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_instance[2].append(mae([a], [b]))\n",
    "                    pca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_kpca = lxdr_kpca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_kpca.T)\n",
    "                    a = x_test_kpca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    kpca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    kpca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    kpca_instance[2].append(mae([a], [b]))\n",
    "                    kpca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_iso = lxdr_iso.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_iso.T)\n",
    "                    a = x_test_iso[instance]\n",
    "                    b = ldrx_instance\n",
    "                    iso_instance[0].append(ed([a], [b])[0][0])\n",
    "                    iso_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    iso_instance[2].append(mae([a], [b]))\n",
    "                    iso_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_ae = lxdr_ae.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_ae.T)\n",
    "                    a = x_test_ae[instance]\n",
    "                    b = ldrx_instance\n",
    "                    ae_instance[0].append(ed([a], [b])[0][0])\n",
    "                    ae_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    ae_instance[2].append(mae([a], [b]))\n",
    "                    ae_instance[3].append(te)\n",
    "\n",
    "                    instance = instance + 1\n",
    "                with open('scalability_final.csv', 'a', encoding='UTF8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    siz = len(x_test)\n",
    "                    writer.writerow([features, 'pca_w', ltype, ng_technique, n, np.mean(pca_weights[0]), np.mean(\n",
    "                        pca_weights[1]), np.mean(pca_weights[2]), np.mean(pca_weights[3])])\n",
    "                    writer.writerow([features, 'pca_i', ltype, ng_technique, n, np.mean(pca_instance[0]), np.mean(\n",
    "                        pca_instance[1]), np.mean(pca_instance[2]), np.mean(pca_instance[3])])\n",
    "                    writer.writerow([features, 'kpca', ltype, ng_technique, n, np.mean(kpca_instance[0]), np.mean(\n",
    "                        kpca_instance[1]), np.mean(kpca_instance[2]), np.mean(kpca_instance[3])])\n",
    "                    writer.writerow([features, 'iso', ltype, ng_technique, n, np.mean(iso_instance[0]), np.mean(\n",
    "                        iso_instance[1]), np.mean(iso_instance[2]), np.mean(iso_instance[3])])\n",
    "                    writer.writerow([features, 'ae', ltype, ng_technique, n, np.mean(ae_instance[0]), np.mean(\n",
    "                        ae_instance[1]), np.mean(ae_instance[2]), np.mean(ae_instance[3])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size: 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# 10, 20, 30, 40 DONE\n",
    "for features in [50]:  # range(150,1050,50): #Edw tha vgei to neural!\n",
    "    print('Feature size:', features)\n",
    "    feature_names = ['F'+str(i) for i in range(features)]\n",
    "    x, y = make_classification(n_samples=1000, n_features=features, n_informative=int(\n",
    "        features/2), n_redundant=int(features/4), n_classes=2, shuffle=True, random_state=1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = MaxAbsScaler().fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    mean = x_train.mean(axis=0)\n",
    "\n",
    "    pca = PCA(int(features/2), random_state=42)\n",
    "    pca.fit(x_train, y_train)\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "\n",
    "    kpca = KernelPCA(int(features/2), random_state=42)\n",
    "    kpca.fit(x_train, y_train)\n",
    "    x_test_kpca = kpca.transform(x_test)\n",
    "\n",
    "    iso = Isomap(n_components=int(features/2))\n",
    "    iso.fit(x_train, y_train)\n",
    "    x_test_iso = iso.transform(x_test)\n",
    "\n",
    "    callback = callbacks.EarlyStopping(\n",
    "        monitor='loss', patience=3, verbose=0, restore_best_weights=True)\n",
    "    ae = Autoencoder(len(x_train[0]), int(features/2))\n",
    "    ae.compile(optimizer='adam', loss='mae')\n",
    "    ae.fit(x_train, x_train,\n",
    "           epochs=200,\n",
    "           shuffle=True,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[callback],\n",
    "           verbose=0)\n",
    "    x_test_ae = ae.predict(x_test)\n",
    "\n",
    "    lxdr_pca = LXDR(pca, feature_names, x_train, mean=mean)\n",
    "    lxdr_kpca = LXDR(kpca, feature_names, x_train)\n",
    "    lxdr_iso = LXDR(iso, feature_names, x_train)\n",
    "    lxdr_ae = LXDR(ae, feature_names, x_train)\n",
    "\n",
    "    for ltype in ['neural']:\n",
    "        lxdr_pca.type = ltype\n",
    "        lxdr_kpca.type = ltype\n",
    "        lxdr_iso.type = ltype\n",
    "        lxdr_ae.type = ltype\n",
    "        for ng_technique in ['KNN']:\n",
    "            number_of_neigbours = [int(3*1000/4)]\n",
    "            if ng_technique == 'Global':\n",
    "                number_of_neigbours = [len(x_train)]\n",
    "                lxdr_pca.global_ = {}\n",
    "                lxdr_kpca.global_ = {}\n",
    "                lxdr_iso.global_ = {}\n",
    "                lxdr_ae.global_ = {}\n",
    "            for n in number_of_neigbours:\n",
    "                pca_weights = [[], [], [], []]\n",
    "                pca_instance = [[], [], [], []]\n",
    "                kpca_instance = [[], [], [], []]\n",
    "                iso_instance = [[], [], [], []]\n",
    "                ae_instance = [[], [], [], []]\n",
    "                instance = 0\n",
    "                for x in x_test:\n",
    "                    ts = time.time()\n",
    "                    weights_pca = lxdr_pca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    a = pca.components_.reshape((1, -1))[0]\n",
    "                    b = np.array(weights_pca).reshape((1, -1))[0]\n",
    "                    pca_weights[0].append(ed([a], [b])[0][0])\n",
    "                    pca_weights[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_weights[2].append(mae([a], [b]))\n",
    "                    pca_weights[3].append(te)\n",
    "                    ldrx_instance = np.dot(x-mean, weights_pca.T)\n",
    "                    a = x_test_pca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    pca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    pca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_instance[2].append(mae([a], [b]))\n",
    "                    pca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_kpca = lxdr_kpca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_kpca.T)\n",
    "                    a = x_test_kpca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    kpca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    kpca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    kpca_instance[2].append(mae([a], [b]))\n",
    "                    kpca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_iso = lxdr_iso.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_iso.T)\n",
    "                    a = x_test_iso[instance]\n",
    "                    b = ldrx_instance\n",
    "                    iso_instance[0].append(ed([a], [b])[0][0])\n",
    "                    iso_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    iso_instance[2].append(mae([a], [b]))\n",
    "                    iso_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_ae = lxdr_ae.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_ae.T)\n",
    "                    a = x_test_ae[instance]\n",
    "                    b = ldrx_instance\n",
    "                    ae_instance[0].append(ed([a], [b])[0][0])\n",
    "                    ae_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    ae_instance[2].append(mae([a], [b]))\n",
    "                    ae_instance[3].append(te)\n",
    "\n",
    "                    instance = instance + 1\n",
    "                with open('scalability_final.csv', 'a', encoding='UTF8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    siz = len(x_test)\n",
    "                    writer.writerow([features, 'pca_w', ltype, ng_technique, n, np.mean(pca_weights[0]), np.mean(\n",
    "                        pca_weights[1]), np.mean(pca_weights[2]), np.mean(pca_weights[3])])\n",
    "                    writer.writerow([features, 'pca_i', ltype, ng_technique, n, np.mean(pca_instance[0]), np.mean(\n",
    "                        pca_instance[1]), np.mean(pca_instance[2]), np.mean(pca_instance[3])])\n",
    "                    writer.writerow([features, 'kpca', ltype, ng_technique, n, np.mean(kpca_instance[0]), np.mean(\n",
    "                        kpca_instance[1]), np.mean(kpca_instance[2]), np.mean(kpca_instance[3])])\n",
    "                    writer.writerow([features, 'iso', ltype, ng_technique, n, np.mean(iso_instance[0]), np.mean(\n",
    "                        iso_instance[1]), np.mean(iso_instance[2]), np.mean(iso_instance[3])])\n",
    "                    writer.writerow([features, 'ae', ltype, ng_technique, n, np.mean(ae_instance[0]), np.mean(\n",
    "                        ae_instance[1]), np.mean(ae_instance[2]), np.mean(ae_instance[3])])\n",
    "    for ltype in ['neural']:\n",
    "        lxdr_pca.type = ltype\n",
    "        lxdr_kpca.type = ltype\n",
    "        lxdr_iso.type = ltype\n",
    "        lxdr_ae.type = ltype\n",
    "        for ng_technique in ['LatentKNN', 'Clustering']:\n",
    "            number_of_neigbours = [10, 50, int(\n",
    "                1000/10), int(1000/5), int(2*1000/4), int(3*1000/4)]\n",
    "            if ng_technique == 'Global':\n",
    "                number_of_neigbours = [len(x_train)]\n",
    "                lxdr_pca.global_ = {}\n",
    "                lxdr_kpca.global_ = {}\n",
    "                lxdr_iso.global_ = {}\n",
    "                lxdr_ae.global_ = {}\n",
    "            for n in number_of_neigbours:\n",
    "                pca_weights = [[], [], [], []]\n",
    "                pca_instance = [[], [], [], []]\n",
    "                kpca_instance = [[], [], [], []]\n",
    "                iso_instance = [[], [], [], []]\n",
    "                ae_instance = [[], [], [], []]\n",
    "                instance = 0\n",
    "                for x in x_test:\n",
    "                    ts = time.time()\n",
    "                    weights_pca = lxdr_pca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    a = pca.components_.reshape((1, -1))[0]\n",
    "                    b = np.array(weights_pca).reshape((1, -1))[0]\n",
    "                    pca_weights[0].append(ed([a], [b])[0][0])\n",
    "                    pca_weights[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_weights[2].append(mae([a], [b]))\n",
    "                    pca_weights[3].append(te)\n",
    "                    ldrx_instance = np.dot(x-mean, weights_pca.T)\n",
    "                    a = x_test_pca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    pca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    pca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    pca_instance[2].append(mae([a], [b]))\n",
    "                    pca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_kpca = lxdr_kpca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_kpca.T)\n",
    "                    a = x_test_kpca[instance]\n",
    "                    b = ldrx_instance\n",
    "                    kpca_instance[0].append(ed([a], [b])[0][0])\n",
    "                    kpca_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    kpca_instance[2].append(mae([a], [b]))\n",
    "                    kpca_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_iso = lxdr_iso.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_iso.T)\n",
    "                    a = x_test_iso[instance]\n",
    "                    b = ldrx_instance\n",
    "                    iso_instance[0].append(ed([a], [b])[0][0])\n",
    "                    iso_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    iso_instance[2].append(mae([a], [b]))\n",
    "                    iso_instance[3].append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_ae = lxdr_ae.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_ae.T)\n",
    "                    a = x_test_ae[instance]\n",
    "                    b = ldrx_instance\n",
    "                    ae_instance[0].append(ed([a], [b])[0][0])\n",
    "                    ae_instance[1].append(1-cd([a], [b])[0][0])\n",
    "                    ae_instance[2].append(mae([a], [b]))\n",
    "                    ae_instance[3].append(te)\n",
    "\n",
    "                    instance = instance + 1\n",
    "                with open('scalability_final.csv', 'a', encoding='UTF8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    siz = len(x_test)\n",
    "                    writer.writerow([features, 'pca_w', ltype, ng_technique, n, np.mean(pca_weights[0]), np.mean(\n",
    "                        pca_weights[1]), np.mean(pca_weights[2]), np.mean(pca_weights[3])])\n",
    "                    writer.writerow([features, 'pca_i', ltype, ng_technique, n, np.mean(pca_instance[0]), np.mean(\n",
    "                        pca_instance[1]), np.mean(pca_instance[2]), np.mean(pca_instance[3])])\n",
    "                    writer.writerow([features, 'kpca', ltype, ng_technique, n, np.mean(kpca_instance[0]), np.mean(\n",
    "                        kpca_instance[1]), np.mean(kpca_instance[2]), np.mean(kpca_instance[3])])\n",
    "                    writer.writerow([features, 'iso', ltype, ng_technique, n, np.mean(iso_instance[0]), np.mean(\n",
    "                        iso_instance[1]), np.mean(iso_instance[2]), np.mean(iso_instance[3])])\n",
    "                    writer.writerow([features, 'ae', ltype, ng_technique, n, np.mean(ae_instance[0]), np.mean(\n",
    "                        ae_instance[1]), np.mean(ae_instance[2]), np.mean(ae_instance[3])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size: 100\n",
      "Let's go!\n",
      "833.4530341625214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# 10, 20, 30, 40 DONE\n",
    "for features in [100]:  # range(150,1050,50): #Edw tha vgei to neural!\n",
    "    print('Feature size:', features)\n",
    "    feature_names = ['F'+str(i) for i in range(features)]\n",
    "    x, y = make_classification(n_samples=1000, n_features=features, n_informative=int(\n",
    "        features/2), n_redundant=int(features/4), n_classes=2, shuffle=True, random_state=1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = MaxAbsScaler().fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    mean = x_train.mean(axis=0)\n",
    "\n",
    "    pca = PCA(int(features/2), random_state=42)\n",
    "    pca.fit(x_train, y_train)\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "\n",
    "    kpca = KernelPCA(int(features/2), random_state=42)\n",
    "    kpca.fit(x_train, y_train)\n",
    "    x_test_kpca = kpca.transform(x_test)\n",
    "\n",
    "    iso = Isomap(n_components=int(features/2))\n",
    "    iso.fit(x_train, y_train)\n",
    "    x_test_iso = iso.transform(x_test)\n",
    "\n",
    "    callback = callbacks.EarlyStopping(\n",
    "        monitor='loss', patience=3, verbose=0, restore_best_weights=True)\n",
    "    ae = Autoencoder(len(x_train[0]), int(features/2))\n",
    "    ae.compile(optimizer='adam', loss='mae')\n",
    "    ae.fit(x_train, x_train,\n",
    "           epochs=200,\n",
    "           shuffle=True,\n",
    "           validation_split=0.1,\n",
    "           callbacks=[callback],\n",
    "           verbose=0)\n",
    "    x_test_ae = ae.predict(x_test)\n",
    "\n",
    "    lxdr_pca = LXDR(pca, feature_names, x_train, mean=mean)\n",
    "    lxdr_kpca = LXDR(kpca, feature_names, x_train)\n",
    "    lxdr_iso = LXDR(iso, feature_names, x_train)\n",
    "    lxdr_ae = LXDR(ae, feature_names, x_train)\n",
    "\n",
    "    print(\"Let's go!\")\n",
    "    for ltype in ['locallocal']:\n",
    "        lxdr_pca.type = ltype\n",
    "        lxdr_kpca.type = ltype\n",
    "        lxdr_iso.type = ltype\n",
    "        lxdr_ae.type = ltype\n",
    "        for ng_technique in ['KNN']:\n",
    "            for n in [int(1000/5)]:\n",
    "\n",
    "                def bob(ind, x_test, n, ng_technique, pca, lxdr_pca, lxdr_kpca, lxdr_iso, lxdr_ae, mean, x_test_pca, x_test_kpca, x_test_iso, x_test_ae):\n",
    "                    result = []\n",
    "                    x = x_test[ind]\n",
    "                    ts = time.time()\n",
    "                    weights_pca = lxdr_pca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    a = pca.components_.reshape((1, -1))[0]\n",
    "                    b = np.array(weights_pca).reshape((1, -1))[0]\n",
    "                    result.append(ed([a], [b])[0][0])\n",
    "                    result.append(1-cd([a], [b])[0][0])\n",
    "                    result.append(mae([a], [b]))\n",
    "                    result.append(te)\n",
    "                    ldrx_instance = np.dot(x-mean, weights_pca.T)\n",
    "                    a = x_test_pca[ind]\n",
    "                    b = ldrx_instance\n",
    "                    result.append(ed([a], [b])[0][0])\n",
    "                    result.append(1-cd([a], [b])[0][0])\n",
    "                    result.append(mae([a], [b]))\n",
    "                    result.append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_kpca = lxdr_kpca.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_kpca.T)\n",
    "                    a = x_test_kpca[ind]\n",
    "                    b = ldrx_instance\n",
    "                    result.append(ed([a], [b])[0][0])\n",
    "                    result.append(1-cd([a], [b])[0][0])\n",
    "                    result.append(mae([a], [b]))\n",
    "                    result.append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_iso = lxdr_iso.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_iso.T)\n",
    "                    a = x_test_iso[ind]\n",
    "                    b = ldrx_instance\n",
    "                    result.append(ed([a], [b])[0][0])\n",
    "                    result.append(1-cd([a], [b])[0][0])\n",
    "                    result.append(mae([a], [b]))\n",
    "                    result.append(te)\n",
    "\n",
    "                    ts = time.time()\n",
    "                    weights_ae = lxdr_ae.explain_instance(\n",
    "                        x, n, auto_alpha=True, ng_technique=ng_technique)\n",
    "                    te = time.time()-ts\n",
    "                    ldrx_instance = np.dot(x, weights_ae.T)\n",
    "                    a = x_test_ae[ind]\n",
    "                    b = ldrx_instance\n",
    "                    result.append(ed([a], [b])[0][0])\n",
    "                    result.append(1-cd([a], [b])[0][0])\n",
    "                    result.append(mae([a], [b]))\n",
    "                    result.append(te)\n",
    "                    return [result]\n",
    "\n",
    "                from joblib import Parallel, delayed\n",
    "                tss = time.time()\n",
    "                with Parallel(n_jobs=4, require='sharedmem') as parallel:\n",
    "                    results = parallel(delayed(bob)(ind, x_test, n, ng_technique, pca, lxdr_pca, lxdr_kpca, lxdr_iso,\n",
    "                                       lxdr_ae, mean, x_test_pca, x_test_kpca, x_test_iso, x_test_ae) for ind in range(len(x_test[:100])))\n",
    "                print(time.time()-tss)\n",
    "                #from multiprocessing import Pool\n",
    "                # with Pool(4) as p:\n",
    "                #    results = p.map(bob, x_test)\n",
    "                \"\"\"\n",
    "                with open('scalability_finalw.csv','a', encoding='UTF8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    siz = len(x_test)\n",
    "                    writer.writerow([features,'pca_w', ltype, ng_technique, n, np.mean(pca_weights[0]), np.mean(pca_weights[1]), np.mean(pca_weights[2]), np.mean(pca_weights[3])])                    \n",
    "                    writer.writerow([features,'pca_i', ltype, ng_technique, n, np.mean(pca_instance[0]), np.mean(pca_instance[1]), np.mean(pca_instance[2]), np.mean(pca_instance[3])])                    \n",
    "                    writer.writerow([features,'kpca', ltype, ng_technique, n, np.mean(kpca_instance[0]), np.mean(kpca_instance[1]), np.mean(kpca_instance[2]), np.mean(kpca_instance[3])])                   \n",
    "                    writer.writerow([features,'iso', ltype, ng_technique, n, np.mean(iso_instance[0]), np.mean(iso_instance[1]), np.mean(iso_instance[2]), np.mean(iso_instance[3])])                   \n",
    "                    writer.writerow([features,'ae', ltype, ng_technique, n, np.mean(ae_instance[0]), np.mean(ae_instance[1]), np.mean(ae_instance[2]), np.mean(ae_instance[3])])                   \n",
    "                \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f818daf8439c2b3310d9a5864c45cd2b306b7bcaedaba213763d725b99fb249"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
